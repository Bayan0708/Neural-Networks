{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción práctica a redes neuronales densas en PyTorch con MNIST\n",
        "\n",
        "### *Universidad Nacional Autónoma de México*\n",
        "## Autor: **Sebastián González Juárez**"
      ],
      "metadata": {
        "id": "CfMG-p2luvNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Idea general\n",
        "\n",
        "**Objetivo**: entrenar una MLP (perceptrón multicapa) sencilla sobre MNIST para clasificar dígitos (0–9).\n",
        "\n",
        "**Flujo**:\n",
        "\n",
        "- Carga y normalización: se descargan las imágenes con torchvision.datasets.MNIST, se convierten a tensores en [0,1] y se aplanan de 1×28×28 a 784.\n",
        "\n",
        "- Batches: se crean DataLoaders con batch_size=128 (barajando el entrenamiento).\n",
        "\n",
        "- Modelo: Linear(784→512) → ReLU → Linear(512→10).\n",
        "\n",
        "- La última capa no usa Softmax; entrega logits.\n",
        "\n",
        "- Pérdida y optimización: nn.CrossEntropyLoss (que integra LogSoftmax) + Adam (lr=1e-3).\n",
        "\n",
        "- Entrenamiento (5 épocas): bucle típico forward → loss → backward → step, registrando loss y accuracy por época.\n",
        "\n",
        "- Predicción rápida: se obtienen probabilidades con F.softmax para inspeccionar un ejemplo.\n",
        "\n",
        "- Evaluación: se calcula la exactitud en test recorriendo el test_loader."
      ],
      "metadata": {
        "id": "hnSfQcnczBVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "yXvl7XLVurww"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UW5UYo2Fs-1S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Datos.\n",
        "\n",
        "Cargar MNIST y preparar como (N, 784) float32/255\n"
      ],
      "metadata": {
        "id": "3h37PzkfvAyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfms = transforms.ToTensor()  # [0,255] -> float32 [0,1]\n",
        "train_ds = datasets.MNIST(root='./data', train=True,  download=True, transform=tfms)\n",
        "test_ds  = datasets.MNIST(root='./data', train=False, download=True, transform=tfms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMAJXfy1vC20",
        "outputId": "0bc3cda7-eff1-4729-d2b0-e3d2959d9da6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 19.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 500kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.46MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos a tensores (N,784) para imitar tu reshape de Keras\n"
      ],
      "metadata": {
        "id": "zE9bPSinvLjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = torch.stack([train_ds[i][0] for i in range(len(train_ds))])  # (60000,1,28,28)\n",
        "train_labels = torch.tensor([train_ds[i][1] for i in range(len(train_ds))]) # (60000,)\n",
        "test_images  = torch.stack([test_ds[i][0]  for i in range(len(test_ds))])   # (10000,1,28,28)\n",
        "test_labels  = torch.tensor([test_ds[i][1] for i in range(len(test_ds))])   # (10000,)"
      ],
      "metadata": {
        "id": "b6RWupEBvIPO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.view(60000, 28*28)  # reshape a (60000, 784)\n",
        "test_images  = test_images.view(10000,  28*28)  # reshape a (10000, 784)\n",
        "# Nota: transforms.ToTensor() ya normalizó a [0,1], así que no dividimos de nuevo por 255."
      ],
      "metadata": {
        "id": "cZEAoK8avVcY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoaders con batch_size=128."
      ],
      "metadata": {
        "id": "bVWfGoG9vZ2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(train_images, train_labels), batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(TensorDataset(test_images,  test_labels),  batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "KX-C8LL0vckt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Modelo:\n",
        "\n",
        "Dense(512,relu)->Dense(10,softmax)"
      ],
      "metadata": {
        "id": "ebWQkmtxvVB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En PyTorch, si usamos CrossEntropyLoss NO ponemos softmax en la capa final (la loss lo aplica internamente)."
      ],
      "metadata": {
        "id": "ZEo3WS6Uvl0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(28*28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "sj2UYWRCvhuC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) Compilación:\n",
        "\n",
        "optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n"
      ],
      "metadata": {
        "id": "yONlF_nOvpyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "akpba5wZvk2q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4) Entrenamiento:\n",
        "\n",
        "epochs=5, batch_size=128 (equivale a model.fit(...))\n"
      ],
      "metadata": {
        "id": "zJ_-XBY_v13c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    correct, total, running_loss = 0, 0, 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        logits = model(xb)                 # forward\n",
        "        loss = criterion(logits, yb)       # CE con labels enteros (sparse)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()                    # backward\n",
        "        optimizer.step()                   # update\n",
        "\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total   += yb.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - loss: {running_loss/total:.4f} - acc: {correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIsRUGdXvuD_",
        "outputId": "2cbaed63-275a-4702-adc1-3feb1e224132"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - loss: 0.3141 - acc: 0.9131\n",
            "Epoch 2 - loss: 0.1251 - acc: 0.9642\n",
            "Epoch 3 - loss: 0.0815 - acc: 0.9764\n",
            "Epoch 4 - loss: 0.0584 - acc: 0.9829\n",
            "Epoch 5 - loss: 0.0432 - acc: 0.9871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Predicción rápida de los primeros 10 test (para emular predict + argmax)\n"
      ],
      "metadata": {
        "id": "1jgAUKXEv9_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_digits = test_images[:10]                    # (10, 784)\n",
        "    logits = model(test_digits)                       # (10, 10)\n",
        "    probs  = F.softmax(logits, dim=1)                 # para ver probabilidades (como tu softmax)\n",
        "    first_probs = probs[0]\n",
        "    print(\"predictions[0] =\", first_probs.numpy())\n",
        "    print(\"predictions[0].argmax() =\", first_probs.argmax().item())\n",
        "    print(\"predictions[0][7] =\", first_probs[7].item())\n",
        "    print(\"test_labels[0] =\", test_labels[0].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBQxV6SHv5vg",
        "outputId": "5ffb68b6-fa29-47fe-bc90-b89ef0dd4097"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions[0] = [1.7907246e-07 5.2774539e-08 7.7493067e-05 7.9781213e-04 1.3021066e-09\n",
            " 8.2873055e-07 1.6382718e-12 9.9909580e-01 1.2581635e-05 1.5155536e-05]\n",
            "predictions[0].argmax() = 7\n",
            "predictions[0][7] = 0.9990957975387573\n",
            "test_labels[0] = 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6) Evaluación (equivale a model.evaluate)"
      ],
      "metadata": {
        "id": "_pRAmUIzwDh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total, running_loss = 0, 0, 0.0\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total   += yb.size(0)"
      ],
      "metadata": {
        "id": "wIY8G78GwE10"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = correct / total\n",
        "print(f\"test_acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUU3xpx0wGvU",
        "outputId": "9d6b2bcc-152b-4a5b-e59d-87f1245987df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_acc: 0.9804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "\n",
        "Con muy poco código se logra una línea base fuerte en MNIST usando PyTorch idiomático.\n",
        "\n",
        "- Separar logits (para la pérdida) y probabilidades (solo para inspección) evita inestabilidades y es la práctica recomendada.\n",
        "\n",
        "- DataLoader + Adam simplifican el entrenamiento y suelen converger rápido con una MLP pequeña.\n",
        "\n",
        "- Esta versión es más robusta y eficiente que una implementación “desde cero”, y sirve como punto de partida para:\n",
        "\n",
        "  - Añadir regularización (Dropout, Weight Decay),\n",
        "\n",
        "  - Probar arquitecturas (más capas, otras activaciones),\n",
        "\n",
        "  - Cambiar a CNNs para exprimir mejor la estructura espacial."
      ],
      "metadata": {
        "id": "Zh61FjZ6zXQb"
      }
    }
  ]
}